{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M423o57VcS9h"
   },
   "outputs": [],
   "source": [
    "!rm -rf torchmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "ij6PEVr0yROc",
    "outputId": "856f7ecf-abfe-4a75-be36-4bf91c33f37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/torchmoji'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects:  25% (1/4)\u001b[K\r",
      "remote: Counting objects:  50% (2/4)\u001b[K\r",
      "remote: Counting objects:  75% (3/4)\u001b[K\r",
      "remote: Counting objects: 100% (4/4)\u001b[K\r",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects:  25% (1/4)\u001b[K\r",
      "remote: Compressing objects:  50% (2/4)\u001b[K\r",
      "remote: Compressing objects:  75% (3/4)\u001b[K\r",
      "remote: Compressing objects: 100% (4/4)\u001b[K\r",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "Receiving objects:   0% (1/147)   \r",
      "Receiving objects:   1% (2/147)   \r",
      "Receiving objects:   2% (3/147)   \r",
      "Receiving objects:   3% (5/147)   \r",
      "Receiving objects:   4% (6/147)   \r",
      "Receiving objects:   5% (8/147)   \r",
      "Receiving objects:   6% (9/147)   \r",
      "Receiving objects:   7% (11/147)   \r",
      "Receiving objects:   8% (12/147)   \r",
      "Receiving objects:   9% (14/147)   \r",
      "Receiving objects:  10% (15/147)   \r",
      "Receiving objects:  11% (17/147)   \r",
      "Receiving objects:  12% (18/147)   \r",
      "Receiving objects:  13% (20/147)   \r",
      "Receiving objects:  14% (21/147)   \r",
      "Receiving objects:  15% (23/147)   \r",
      "Receiving objects:  16% (24/147)   \r",
      "Receiving objects:  17% (25/147)   \r",
      "Receiving objects:  18% (27/147)   \r",
      "Receiving objects:  19% (28/147)   \r",
      "Receiving objects:  20% (30/147)   \r",
      "Receiving objects:  21% (31/147)   \r",
      "Receiving objects:  22% (33/147)   \r",
      "Receiving objects:  23% (34/147)   \r",
      "Receiving objects:  24% (36/147)   \r",
      "Receiving objects:  25% (37/147)   \r",
      "Receiving objects:  26% (39/147)   \r",
      "Receiving objects:  27% (40/147)   \r",
      "Receiving objects:  28% (42/147)   \r",
      "Receiving objects:  29% (43/147)   \r",
      "Receiving objects:  30% (45/147)   \r",
      "Receiving objects:  31% (46/147)   \r",
      "Receiving objects:  32% (48/147)   \r",
      "Receiving objects:  33% (49/147)   \r",
      "Receiving objects:  34% (50/147)   \r",
      "Receiving objects:  35% (52/147)   \r",
      "Receiving objects:  36% (53/147)   \r",
      "Receiving objects:  37% (55/147)   \r",
      "Receiving objects:  38% (56/147)   \r",
      "Receiving objects:  39% (58/147)   \r",
      "Receiving objects:  40% (59/147)   \r",
      "Receiving objects:  41% (61/147)   \r",
      "Receiving objects:  42% (62/147)   \r",
      "Receiving objects:  43% (64/147)   \r",
      "Receiving objects:  44% (65/147)   \r",
      "Receiving objects:  45% (67/147)   \r",
      "Receiving objects:  46% (68/147)   \r",
      "remote: Total 147 (delta 0), reused 0 (delta 0), pack-reused 143\u001b[K\n",
      "Receiving objects:  47% (70/147)   \r",
      "Receiving objects:  48% (71/147)   \r",
      "Receiving objects:  49% (73/147)   \r",
      "Receiving objects:  50% (74/147)   \r",
      "Receiving objects:  51% (75/147)   \r",
      "Receiving objects:  52% (77/147)   \r",
      "Receiving objects:  53% (78/147)   \r",
      "Receiving objects:  54% (80/147)   \r",
      "Receiving objects:  55% (81/147)   \r",
      "Receiving objects:  56% (83/147)   \r",
      "Receiving objects:  57% (84/147)   \r",
      "Receiving objects:  58% (86/147)   \r",
      "Receiving objects:  59% (87/147)   \r",
      "Receiving objects:  60% (89/147)   \r",
      "Receiving objects:  61% (90/147)   \r",
      "Receiving objects:  62% (92/147)   \r",
      "Receiving objects:  63% (93/147)   \r",
      "Receiving objects:  64% (95/147)   \r",
      "Receiving objects:  65% (96/147)   \r",
      "Receiving objects:  66% (98/147)   \r",
      "Receiving objects:  67% (99/147)   \r",
      "Receiving objects:  68% (100/147)   \r",
      "Receiving objects:  69% (102/147)   \r",
      "Receiving objects:  70% (103/147)   \r",
      "Receiving objects:  71% (105/147)   \r",
      "Receiving objects:  72% (106/147)   \r",
      "Receiving objects:  73% (108/147)   \r",
      "Receiving objects:  74% (109/147)   \r",
      "Receiving objects:  75% (111/147)   \r",
      "Receiving objects:  76% (112/147)   \r",
      "Receiving objects:  77% (114/147)   \r",
      "Receiving objects:  78% (115/147)   \r",
      "Receiving objects:  79% (117/147)   \r",
      "Receiving objects:  80% (118/147)   \r",
      "Receiving objects:  81% (120/147)   \r",
      "Receiving objects:  82% (121/147)   \r",
      "Receiving objects:  83% (123/147)   \r",
      "Receiving objects:  84% (124/147)   \r",
      "Receiving objects:  85% (125/147)   \r",
      "Receiving objects:  86% (127/147)   \r",
      "Receiving objects:  87% (128/147)   \r",
      "Receiving objects:  88% (130/147)   \r",
      "Receiving objects:  89% (131/147)   \r",
      "Receiving objects:  90% (133/147)   \r",
      "Receiving objects:  91% (134/147)   \r",
      "Receiving objects:  92% (136/147)   \r",
      "Receiving objects:  93% (137/147)   \r",
      "Receiving objects:  94% (139/147)   \r",
      "Receiving objects:  95% (140/147)   \r",
      "Receiving objects:  96% (142/147)   \r",
      "Receiving objects:  97% (143/147)   \r",
      "Receiving objects:  98% (145/147)   \r",
      "Receiving objects:  99% (146/147)   \r",
      "Receiving objects: 100% (147/147)   \r",
      "Receiving objects: 100% (147/147), 2.42 MiB | 12.13 MiB/s, done.\n",
      "Resolving deltas:   0% (0/49)   \r",
      "Resolving deltas:   2% (1/49)   \r",
      "Resolving deltas:   8% (4/49)   \r",
      "Resolving deltas:  10% (5/49)   \r",
      "Resolving deltas:  16% (8/49)   \r",
      "Resolving deltas:  18% (9/49)   \r",
      "Resolving deltas:  20% (10/49)   \r",
      "Resolving deltas:  22% (11/49)   \r",
      "Resolving deltas:  24% (12/49)   \r",
      "Resolving deltas:  26% (13/49)   \r",
      "Resolving deltas:  30% (15/49)   \r",
      "Resolving deltas:  32% (16/49)   \r",
      "Resolving deltas:  34% (17/49)   \r",
      "Resolving deltas:  36% (18/49)   \r",
      "Resolving deltas:  38% (19/49)   \r",
      "Resolving deltas:  48% (24/49)   \r",
      "Resolving deltas:  63% (31/49)   \r",
      "Resolving deltas:  97% (48/49)   \r",
      "Resolving deltas: 100% (49/49)   \r",
      "Resolving deltas: 100% (49/49), done.\n"
     ]
    }
   ],
   "source": [
    "![ ! -d \"/content/torchmoji\" ] && mkdir -p torchmoji && git clone https://github.com/MikhailKazekin/torchMoji.git /content/torchmoji/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lR-VyH32QMUS",
    "outputId": "5981edc7-f65d-4741-c5e8-507aecb27f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'MikhailKazekin-issue-34' set up to track remote branch 'MikhailKazekin-issue-34' from 'origin'.\n",
      "Switched to a new branch 'MikhailKazekin-issue-34'\n",
      "Processing /content/torchmoji\n",
      "Collecting emoji==0.4.5\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/0c/c3d24c913986271484fe85446a158ab7b5ff068daa5c2e0ba8793116eed6/emoji-0.4.5.tar.gz\n",
      "Collecting numpy==1.13.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/e2/57c1a6af4ff0ac095dd68b12bf07771813dbf401faf1b97f5fc0cb963647/numpy-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.0MB 6.0MB/s \n",
      "\u001b[?25hCollecting scipy==0.19.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/46/da8d7166102d29695330f7c0b912955498542988542c0d2ae3ea0389c68d/scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.2MB 1.3MB/s \n",
      "\u001b[?25hCollecting scikit-learn==0.19.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/b3/209652a5d60ce4a2a8a35ad893d7565bbb0f87ce043264ba5c9e7de304cd/scikit_learn-0.19.0-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.4MB 9.1MB/s \n",
      "\u001b[?25hCollecting text-unidecode==1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/c7a477228b2162937f200ece3793bb21c0f21f66b00fc010cdeb93cf465b/text_unidecode-1.0-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 50.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: torchmoji, emoji\n",
      "  Building wheel for torchmoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchmoji: filename=torchmoji-1.0-cp36-none-any.whl size=36066 sha256=d66650a0fb2cfbe1fcf42c13be343c0b94ed58dc92a20dbdbd0460b45193bb8a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ez19r_n9/wheels/e0/c2/a0/6fb42f01e31ceee4e33f023de9a52ebd68d7d3c8cda51d3366\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.4.5-cp36-none-any.whl size=38198 sha256=221af82ab2707eb92295d9e877f690653685c9966a1887aad4c1d8aa777dc980\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ez19r_n9/wheels/82/5f/75/d3b84d3c13409f43533b70af38ca20abb09f7ffb0aaf051e33\n",
      "Successfully built torchmoji emoji\n",
      "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: umap-learn 0.4.4 has requirement numpy>=1.17, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: umap-learn 0.4.4 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: umap-learn 0.4.4 has requirement scipy>=1.3.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tifffile 2020.6.3 has requirement numpy>=1.15.1, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: seaborn 0.10.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pywavelets 1.1.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: python-slugify 4.0.0 has requirement text-unidecode>=1.3, but you'll have text-unidecode 1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyarrow 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas 1.0.4 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: librosa 0.6.3 has requirement scikit-learn!=0.19.0,>=0.14.0, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fancyimpute 0.4.3 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: astropy 4.0.1.post1 has requirement numpy>=1.16, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: emoji, numpy, scipy, scikit-learn, text-unidecode, torchmoji\n",
      "  Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Found existing installation: text-unidecode 1.3\n",
      "    Uninstalling text-unidecode-1.3:\n",
      "      Successfully uninstalled text-unidecode-1.3\n",
      "Successfully installed emoji-0.4.5 numpy-1.13.1 scikit-learn-0.19.0 scipy-0.19.1 text-unidecode-1.0 torchmoji-1.0\n"
     ]
    }
   ],
   "source": [
    " !cd /content/torchmoji && git checkout --track origin/MikhailKazekin-issue-34 && pip install --no-cache-dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "yjYwiexQzaYq",
    "outputId": "a055033e-19d8-44b8-ea9c-2fdd68bede4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to download the pretrained weights file from https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0#\n",
      "The size of the file is roughly 85MB. Continue? [y/n]\n",
      "y\n",
      "Downloading...\n",
      "Running system call: wget https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0# -O /content/torchmoji/model/pytorch_model.bin\n",
      "--2020-06-19 17:08:07--  https://www.dropbox.com/s/q8lax9ary32c7t9/pytorch_model.bin?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/q8lax9ary32c7t9/pytorch_model.bin [following]\n",
      "--2020-06-19 17:08:07--  https://www.dropbox.com/s/raw/q8lax9ary32c7t9/pytorch_model.bin\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com/cd/0/inline/A593RzDbXaJLRlKoFeUGZazt9WSrzF_ZOZT6xn7Md1kaLEl4iBMM0ka1ApbGQwjytgmMNvzh1oX3TohOw9kZpYEwca2W9Q1YYmDqBmkwaYUzFw/file# [following]\n",
      "--2020-06-19 17:08:08--  https://uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com/cd/0/inline/A593RzDbXaJLRlKoFeUGZazt9WSrzF_ZOZT6xn7Md1kaLEl4iBMM0ka1ApbGQwjytgmMNvzh1oX3TohOw9kZpYEwca2W9Q1YYmDqBmkwaYUzFw/file\n",
      "Resolving uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com (uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
      "Connecting to uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com (uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/A5-URheDffx9R_wPtbEfGe4FQchAJDoE7qHIs2cJaBH-PUShboC74YuhCf1Hx-4xlha0dDv-dGG1XW2oeZ48Q-_VqwrDktbRw8-NSbhc4IDkjZjQB0yDgQK8aYooZgzRmgFUG1UUNk4dqGjWmvqPQt7csNF92eku4tgqtmHBiQ87VBeXPqw80imv04yxucv8ZBcXqMIIYB9FjTVMubOf4r00cTQ0s6AKeqQRRL7fv-GIr1pglOdvBc9dYP6lrLYwoLfpvKuGNfBHn_ZpNFeXEOgpLQL-ywHaHezbTn3fYaETcNIoK7UzJA-XkEHr3rRqwJGdrkoiLtC1n8Ul-0C1qqJ3/file [following]\n",
      "--2020-06-19 17:08:08--  https://uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com/cd/0/inline2/A5-URheDffx9R_wPtbEfGe4FQchAJDoE7qHIs2cJaBH-PUShboC74YuhCf1Hx-4xlha0dDv-dGG1XW2oeZ48Q-_VqwrDktbRw8-NSbhc4IDkjZjQB0yDgQK8aYooZgzRmgFUG1UUNk4dqGjWmvqPQt7csNF92eku4tgqtmHBiQ87VBeXPqw80imv04yxucv8ZBcXqMIIYB9FjTVMubOf4r00cTQ0s6AKeqQRRL7fv-GIr1pglOdvBc9dYP6lrLYwoLfpvKuGNfBHn_ZpNFeXEOgpLQL-ywHaHezbTn3fYaETcNIoK7UzJA-XkEHr3rRqwJGdrkoiLtC1n8Ul-0C1qqJ3/file\n",
      "Reusing existing connection to uc0852ca9c72253062660644bb65.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89616062 (85M) [application/octet-stream]\n",
      "Saving to: ‚Äò/content/torchmoji/model/pytorch_model.bin‚Äô\n",
      "\n",
      "/content/torchmoji/ 100%[===================>]  85.46M  47.2MB/s    in 1.8s    \n",
      "\n",
      "2020-06-19 17:08:11 (47.2 MB/s) - ‚Äò/content/torchmoji/model/pytorch_model.bin‚Äô saved [89616062/89616062]\n",
      "\n",
      "Downloaded weights to ../model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "! cd /content/torchmoji/scripts && python download_weights.py && cd /content/torchmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L7Aqy9yuzcwd",
    "outputId": "59692656-dfb6-46fb-ad50-ebe685be9b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin  vocabulary.json\n"
     ]
    }
   ],
   "source": [
    "!ls /content/torchmoji/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "mjp2MlJVdaOO",
    "outputId": "7b73d95c-a86f-43c7-cac8-81f1e5533478",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing using dictionary from ./model/vocabulary.json\n",
      "Loading model from ./model/pytorch_model.bin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishak/Projects/Playground/torchMoji/torchmoji/model_def.py:159: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(self.embed.weight.data, a=-0.5, b=0.5)\n",
      "/home/mishak/Projects/Playground/torchMoji/torchmoji/model_def.py:161: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(t)\n",
      "/home/mishak/Projects/Playground/torchMoji/torchmoji/model_def.py:163: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  nn.init.orthogonal(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for embed.weight\n",
      "Loading weights for lstm_0.weight_ih_l0\n",
      "Loading weights for lstm_0.weight_hh_l0\n",
      "Loading weights for lstm_0.bias_ih_l0\n",
      "Loading weights for lstm_0.bias_hh_l0\n",
      "Loading weights for lstm_0.weight_ih_l0_reverse\n",
      "Loading weights for lstm_0.weight_hh_l0_reverse\n",
      "Loading weights for lstm_0.bias_ih_l0_reverse\n",
      "Loading weights for lstm_0.bias_hh_l0_reverse\n",
      "Loading weights for lstm_1.weight_ih_l0\n",
      "Loading weights for lstm_1.weight_hh_l0\n",
      "Loading weights for lstm_1.bias_ih_l0\n",
      "Loading weights for lstm_1.bias_hh_l0\n",
      "Loading weights for lstm_1.weight_ih_l0_reverse\n",
      "Loading weights for lstm_1.weight_hh_l0_reverse\n",
      "Loading weights for lstm_1.bias_ih_l0_reverse\n",
      "Loading weights for lstm_1.bias_hh_l0_reverse\n",
      "Loading weights for attention_layer.attention_vector\n",
      "Ignoring weights for output_layer.0.weight\n",
      "Ignoring weights for output_layer.0.bias\n",
      "TorchMoji(\n",
      "  (embed): Embedding(50000, 256)\n",
      "  (embed_dropout): Dropout2d(p=0, inplace=False)\n",
      "  (lstm_0): LSTMHardSigmoid(256, 512, batch_first=True, bidirectional=True)\n",
      "  (lstm_1): LSTMHardSigmoid(1024, 512, batch_first=True, bidirectional=True)\n",
      "  (attention_layer): Attention(2304, return attention=False)\n",
      ")\n",
      "Encoding texts..\n",
      "First 5 dimensions for sentence: I love mom's cooking\n",
      "[-0.00852921  0.05861182  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishak/Projects/Playground/torchMoji/torchmoji/model_def.py:165: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(t, 0)\n",
      "/home/mishak/Projects/Playground/torchMoji/venv/dev/lib/python3.6/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Use torchMoji to encode texts into emotional feature vectors.\n",
    "\"\"\"\n",
    "from __future__ import print_function, division, unicode_literals\n",
    "import json\n",
    "\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from torchmoji.model_def import torchmoji_feature_encoding\n",
    "#from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "VOCAB_PATH = './model/vocabulary.json'\n",
    "PRETRAINED_PATH = './model/pytorch_model.bin'\n",
    "\n",
    "TEST_SENTENCES = ['I love mom\\'s cooking',\n",
    "                  'I love how you never reply back..',\n",
    "                  'I love cruising with my homies',\n",
    "                  'I love messing with yo mind!!',\n",
    "                  'I love you and now you\\'re just gone..',\n",
    "                  'This is shit',\n",
    "                  'This is the shit']\n",
    "\n",
    "maxlen = 30\n",
    "batch_size = 32\n",
    "\n",
    "print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "st = SentenceTokenizer(vocabulary, maxlen)\n",
    "tokenized, _, _ = st.tokenize_sentences(TEST_SENTENCES)\n",
    "\n",
    "#print(tokenized)\n",
    "#print(type(tokenized))\n",
    "#print(tokenized.shape)\n",
    "\n",
    "print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "model = torchmoji_feature_encoding(PRETRAINED_PATH)\n",
    "print(model)\n",
    "\n",
    "print('Encoding texts..')\n",
    "encoding = model(tokenized)\n",
    "\n",
    "print('First 5 dimensions for sentence: {}'.format(TEST_SENTENCES[0]))\n",
    "print(encoding[0,:5])\n",
    "\n",
    "# Now you could visualize the encodings to see differences,\n",
    "# run a logistic regression classifier on top,\n",
    "# or basically anything you'd like to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "781471d81b7449c28ca2a504e510d3b6",
      "5581ce9011a74f12a2bf76f34f9542d1",
      "2d63921532bf43c7b07df82e0f8816e3"
     ]
    },
    "colab_type": "code",
    "id": "dQVbZP7og2xV",
    "outputId": "813c06b4-3480-475f-b3de-a76670356960",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishak/Projects/Playground/torchMoji/torchmoji/model_def.py:167: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(self.output_layer[0].weight.data)\n",
      "/home/mishak/Projects/Playground/torchMoji/venv/dev/lib/python3.6/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca85054ed1842d5a758f8d48a13b27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<html><head><meta charset=\"UTF-8\"></head><body>You know what else is heating up?  A boycott of you‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import emoji\n",
    "\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from torchmoji.model_def import torchmoji_emojis\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Emoji map in emoji_overview.png\n",
    "EMOJIS = \":joy: :unamused: :weary: :sob: :heart_eyes: \\\n",
    ":pensive: :ok_hand: :blush: :heart: :smirk: \\\n",
    ":grin: :notes: :flushed: :100: :sleeping: \\\n",
    ":relieved: :relaxed: :raised_hands: :two_hearts: :expressionless: \\\n",
    ":sweat_smile: :pray: :confused: :kissing_heart: :heartbeat: \\\n",
    ":neutral_face: :information_desk_person: :disappointed: :see_no_evil: :tired_face: \\\n",
    ":v: :sunglasses: :rage: :thumbsup: :cry: \\\n",
    ":sleepy: :yum: :triumph: :hand: :mask: \\\n",
    ":clap: :eyes: :gun: :persevere: :smiling_imp: \\\n",
    ":sweat: :broken_heart: :yellow_heart: :musical_note: :speak_no_evil: \\\n",
    ":wink: :skull: :confounded: :smile: :stuck_out_tongue_winking_eye: \\\n",
    ":angry: :no_good: :muscle: :facepunch: :purple_heart: \\\n",
    ":sparkling_heart: :blue_heart: :grimacing: :sparkles:\".split(' ')\n",
    "\n",
    "def top_elements(array, k):\n",
    "    ind = np.argpartition(array, -k)[-k:]\n",
    "    return ind[np.argsort(array[ind])][::-1]\n",
    "\n",
    "MAX_LEN = 300\n",
    "\n",
    "text = \"You know what else is heating up?  A boycott of your services because this company is run by bigots who lick the boots of BLM and Antifa.\"\n",
    "\n",
    "# Tokenizing using dictionary\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "\n",
    "st = SentenceTokenizer(vocabulary, MAX_LEN)\n",
    "\n",
    "# Loading model\n",
    "model = torchmoji_emojis(PRETRAINED_PATH)\n",
    "# Running predictions\n",
    "tokenized, _, _ = st.tokenize_sentences([text])\n",
    "# Get sentence probability\n",
    "prob = model(tokenized)[0]\n",
    "\n",
    "# Top emoji id\n",
    "emoji_ids = top_elements(prob, 5)\n",
    "\n",
    "# map to emojis\n",
    "emojis = map(lambda x: EMOJIS[x], emoji_ids)\n",
    "\n",
    "out_text = emoji.emojize(\"{} {}\".format(text,' '.join(emojis)), use_aliases=False)\n",
    "widgets.HTML(\n",
    "    value=f'<html><head><meta charset=\"UTF-8\"></head><body>{out_text}</body></html>',\n",
    "    placeholder='Some HTML',\n",
    "    description='Some HTML',\n",
    ")\n",
    "# out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fEL6T2yhkFQN",
    "outputId": "18f387e7-22c7-4ebc-ca29-22c141030b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is üëç\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize('Python is :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "·Ω†0\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u1F600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji.emojize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":rage:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize(\":rage:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727bc5befdcf4c82a5daf79a8dd7d6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<html><head><meta charset=\"UTF-8\"></head><body><p style=\"font-size: 30px; font-family:\\'Segoe UI E‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.HTML(\n",
    "    value=f\"\"\"\n",
    "    <html>\n",
    "        <head>\n",
    "            <script src=\"https://twemoji.maxcdn.com/v/latest/twemoji.min.js\" crossorigin=\"anonymous\"></script>\n",
    "            <meta charset=\"UTF-8\">\n",
    "        </head>\n",
    "        <body>\n",
    "            <p style=\"font-size: 30px; font-family:\\'Segoe UI Emoji\\'\">I \\u2764\\uFE0F emoji!</p>\n",
    "        </body>\n",
    "    </html>\"\"\",\n",
    "    placeholder='Some HTML',\n",
    "    description='Some HTML',\n",
    ")\n",
    "# out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jn5z2dCi0JVS"
   },
   "outputs": [],
   "source": [
    "wiki_url = 'https://en.wikipedia.org/wiki/Special:Export/Train'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_moji_exploration_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('dev': virtualenv)",
   "language": "python",
   "name": "python36964bitdevvirtualenv531f5e49aaf54d6489ab76e5548069e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d63921532bf43c7b07df82e0f8816e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5581ce9011a74f12a2bf76f34f9542d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "781471d81b7449c28ca2a504e510d3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "Some HTML",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d63921532bf43c7b07df82e0f8816e3",
      "placeholder": "Some HTML",
      "style": "IPY_MODEL_5581ce9011a74f12a2bf76f34f9542d1",
      "value": "<html><head><meta charset=\"UTF-8\"></head><body>You know what else is heating up?  A boycott of your services because this company is run by bigots who lick the boots of BLM and Antifa. :rage: :angry: :triumph: :expressionless: :mask:</body></html>"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
